---
title: "Analisis overfitting"
author: "Jimena Murillo"
date: '2022-06-15'
output:
  pdf_document: default
  html_document: default
---

### Paquetes

```{r}
library(keras) # for deep learning
library(tidyverse) # general utility functions
library(caret) # machine learning utility functions
library(tibble)
library(readr)
library(ggplot2)
library(tensorflow)
library(neuralnet)

```


## Datos

```{r}

load("C:/Users/usuario1/Desktop/CIMPA/Github_CIMPA/PRACTICA_CIMPA/base_cantones.RData")


Alajuela <- basecanton %>% filter(Canton == "Alajuela") %>% 
  
  dplyr::select(Year,Month,Nino12SSTA, Nino3SSTA, Nino4SSTA,Nino34SSTA,Nino34SSTA1, Nino34SSTA2, Nino34SSTA3, Nino34SSTA4, Nino34SSTA5, Nino34SSTA6, TNA, TNA1,TNA2, EVI, NDVI, NDVI1, NDVI2, NDWI, LSD, LSD1, LSD2, LSN, Precip_t, Precip_t1, Precip_t2, Precip_t3, Precip_t4, Precip_t5, Precip_t6, RRl1, RR) %>% 
  
  arrange(Year,Month) %>% ungroup() %>% mutate(Month=as.numeric(Month))


if(anyNA(Alajuela)){
  Alajuela <- na.omit(Alajuela)
}

#Escala


normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

denorm <- function(x) {
  return (x*(max(Alajuela$RR) - min(Alajuela$RR))+min(Alajuela$RR))
}

Alajuela2 <- apply(Alajuela, 2, normalize)

Fecha = paste(Alajuela$Year, Alajuela$Month)
Fechas_nom = c(2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011) 

```


```{r}


model.gen = function(X_train,y_train, X_test){

## Generar un Wrapper para el learning dropout
# R6 wrapper class, a subclass of KerasWrapper
ConcreteDropout <- R6::R6Class("ConcreteDropout",
  
  inherit = KerasWrapper,
  
  public = list(
    weight_regularizer = NULL,
    dropout_regularizer = NULL,
    init_min = NULL,
    init_max = NULL,
    is_mc_dropout = NULL,
    supports_masking = TRUE,
    p_logit = NULL,
    p = NULL,
    
    initialize = function(weight_regularizer,
                          dropout_regularizer,
                          init_min,
                          init_max,
                          is_mc_dropout) {
      self$weight_regularizer <- weight_regularizer
      self$dropout_regularizer <- dropout_regularizer
      self$is_mc_dropout <- is_mc_dropout
      self$init_min <- k_log(init_min) - k_log(1 - init_min)
      self$init_max <- k_log(init_max) - k_log(1 - init_max)
    },
    
    build = function(input_shape) {
      super$build(input_shape)
      
      self$p_logit <- super$add_weight(
        name = "p_logit",
        shape = shape(1),
        initializer = initializer_random_uniform(self$init_min, self$init_max),
        trainable = TRUE
      )

      self$p <- k_sigmoid(self$p_logit)

      input_dim <- input_shape[[2]]

      weight <- private$py_wrapper$layer$kernel
      
      kernel_regularizer <- self$weight_regularizer * 
                            k_sum(k_square(weight)) / 
                            (1 - self$p)
      
      dropout_regularizer <- self$p * k_log(self$p)
      dropout_regularizer <- dropout_regularizer +  
                             (1 - self$p) * k_log(1 - self$p)
      dropout_regularizer <- dropout_regularizer * 
                             self$dropout_regularizer * 
                             k_cast(input_dim, k_floatx())

      regularizer <- k_sum(kernel_regularizer + dropout_regularizer)
      super$add_loss(regularizer)
    },
    
    concrete_dropout = function(x) {
      eps <- k_cast_to_floatx(k_epsilon())
      temp <- 0.1
      
      unif_noise <- k_random_uniform(shape = k_shape(x))
      
      drop_prob <- k_log(self$p + eps) - 
                   k_log(1 - self$p + eps) + 
                   k_log(unif_noise + eps) - 
                   k_log(1 - unif_noise + eps)
      drop_prob <- k_sigmoid(drop_prob / temp)
      
      random_tensor <- 1 - drop_prob
      
      retain_prob <- 1 - self$p
      x <- x * random_tensor
      x <- x / retain_prob
      x
    },

    call = function(x, mask = NULL, training = NULL) {
      if (self$is_mc_dropout) {
        super$call(self$concrete_dropout(x))
      } else {
        k_in_train_phase(
          function()
            super$call(self$concrete_dropout(x)),
          super$call(x),
          training = training
        )
      }
    }
  )
)

# function for instantiating custom wrapper
layer_concrete_dropout <- function(object, 
                                   layer,
                                   weight_regularizer = 1e-6,
                                   dropout_regularizer = 1e-5,
                                   init_min = 0.1,
                                   init_max = 0.1,
                                   is_mc_dropout = TRUE,
                                   name = NULL,
                                   trainable = TRUE) {
  create_wrapper(ConcreteDropout, object, list(
    layer = layer,
    weight_regularizer = weight_regularizer,
    dropout_regularizer = dropout_regularizer,
    init_min = init_min,
    init_max = init_max,
    is_mc_dropout = is_mc_dropout,
    name = name,
    trainable = trainable
  ))
}



# prior length-scale
l <- 1e-4
# initial value for weight regularizer 
wd <- l^2/230
# initial value for dropout regularizer
dd <- 2/230



## Modelo Dropout


# we use one-dimensional input data here, but this isn't a necessity
input_dim <- 32
# this too could be > 1 if we wanted
output_dim <- 1


input <- layer_input(shape = input_dim)

output <- input %>% layer_concrete_dropout(
  layer = layer_dense(units = 100, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
  ) %>% layer_concrete_dropout(
  layer = layer_dense(units = 50, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
  ) %>% layer_concrete_dropout(
  layer = layer_dense(units = 50, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
) %>% layer_concrete_dropout(
  layer = layer_dense(units = 50, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
) %>% layer_concrete_dropout(
  layer = layer_dense(units = 25, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
) %>% layer_concrete_dropout(
  layer = layer_dense(units = 25, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
) %>% layer_concrete_dropout(
  layer = layer_dense(units = 25, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
) %>% layer_concrete_dropout(
  layer = layer_dense(units = 12, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
) %>% layer_concrete_dropout(
  layer = layer_dense(units = 12, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
) %>% layer_concrete_dropout(
  layer = layer_dense(units = 6, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
) %>% layer_concrete_dropout(
  layer = layer_dense(units = 6, activation = "relu"),
  weight_regularizer = wd,
  dropout_regularizer = dd
)


## Output del Modelo


mean <- output %>% layer_concrete_dropout(
  layer = layer_dense(units = output_dim),
  weight_regularizer = wd,
  dropout_regularizer = dd
)

log_var <- output %>% layer_concrete_dropout(
  layer_dense(units = output_dim),
  weight_regularizer = wd,
  dropout_regularizer = dd
)


output <- layer_concatenate(list(mean, log_var))

model <- keras_model(input, output)


## Entrenar al modelo


model %>% compile(
  optimizer = "adam",
  loss = "mse",
  metrics = "mae")

history <- model %>% fit(
  X_train,
  y_train,
  epochs = 100,
  batch_size = 18,
  validation_split = 0.1,
  shuffle = F
)


num_MC_samples <- 300

samples = list()

MC_samples.pd <- array(0, dim = c(num_MC_samples, nrow(X_test), 2 * output_dim))
for (k in 1:num_MC_samples) {
  MC_samples.pd[k, , ] <- denorm((model %>% predict(X_test)))
}

MC_samples.tn <- array(0, dim = c(num_MC_samples, nrow(X_train), 2 * output_dim))
for (k in 1:num_MC_samples) {
  MC_samples.tn[k, , ] <- denorm((model %>% predict(X_train)))
}

MC_samples.tot <- array(0, dim = c(num_MC_samples, nrow(Alajuela2[,-33]), 2 * output_dim))
for (k in 1:num_MC_samples) {
  MC_samples.tot[k, , ] <- denorm((model %>% predict(Alajuela2[,-33])))
}


samples[[1]] <- MC_samples.pd
samples[[2]] <- MC_samples.tn
samples[[3]] <- MC_samples.tot

return (samples)

}

```

```{r}
#Train y test

Fechas = c(1, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50)


Eval.pd = matrix(NA, nrow = length(Fechas), ncol = 2)
Eval.tn = matrix(NA, nrow = length(Fechas), ncol = 2)
Eval.tot = matrix(NA, nrow = length(Fechas), ncol = 2)

p1 = list()
p2 = list()
p3 = list()

for (i in 1:length(Fechas)) {

data_train = as.data.frame(Alajuela2) %>% filter(Year < Fechas[i])#PARA ENTRENAR HASTA 2018
data_test = as.data.frame(Alajuela2) %>% filter(Year >= Fechas[])

X_train = as.matrix(data_train[,-ncol(data_train)])
y_train = as.matrix(data_train[,ncol(data_train)])

X_test = as.matrix(data_test[,-ncol(data_test)])
y_test = as.matrix(data_test[,ncol(data_test)])

samples = list()
samples = model.gen (X_train, y_train, X_test)

## Generar intervalo de confianza
output_dim  = 1

MC_samples.pd = samples[[1]]

means <- NULL
means <- MC_samples.pd[, , 1:output_dim]  
# average over the MC samples
predictive_mean <- apply(means, 2, mean) 

epistemic_uncertainty <- apply(means, 2, var) 

logvar = NULL
logvar <- MC_samples.pd[, , (output_dim + 1):(output_dim * 2)]
aleatoric_uncertainty <- exp(colMeans(logvar))

y_test = denorm(y_test)


df1 <- data.frame(
  x = Fecha[(236-nrow(X_test)):235],
  y = y_test,
  y_pred = predictive_mean,
  e_u_lower = predictive_mean - sqrt(epistemic_uncertainty),
  e_u_upper = predictive_mean + sqrt(epistemic_uncertainty),
  a_u_lower = predictive_mean - sqrt(aleatoric_uncertainty),
  a_u_upper = predictive_mean + sqrt(aleatoric_uncertainty),
  u_overall_lower = predictive_mean - 
                    sqrt(epistemic_uncertainty) - 
                    sqrt(aleatoric_uncertainty),
  u_overall_upper = predictive_mean + 
                    sqrt(epistemic_uncertainty) + 
                    sqrt(aleatoric_uncertainty)
)



everyother1 <- function(x) x[(seq_along(Fecha) + 5)%%12 == 6]


p1[[i]] = ggplot(df1, aes(x = x, y = y, group = 1)) + geom_line(colour = "blue") + 
  geom_line( aes(x = x, y = y_pred, colour = "red"))+   
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
  panel.background = element_blank(), axis.text.x = element_text(angle = 45), legend.position = "none" )+
  scale_x_discrete(breaks = everyother1) + labs (x = "Fecha", y = "Riesgo Relativo") +
  ggtitle(paste("Predicciones desde año:", Fechas_nom[i], sep = " "))+
  geom_ribbon(aes(ymin = u_overall_lower, ymax = u_overall_upper), alpha = 0.3) +
  ylim(-3, 10)

metricas <- function(tabla){
  NRMSE <- mean((tabla$y_pred-tabla$y)^2)/mean(tabla$y)
  NIS_95 <- mean((tabla$u_overall_upper-tabla$u_overall_lower)+
                   (2/0.05)*(tabla$u_overall_lower-tabla$y)*(tabla$y<tabla$u_overall_lower)+
                   (2/0.05)*(tabla$y-tabla$u_overall_upper)*(tabla$y>tabla$u_overall_upper))/mean(tabla$y)
  return(data.frame(NRMSE,NIS_95))
}

Eval.pd[i, 1:2] = as.numeric(metricas(df1))





#### PREDICCIONES CON X_TRAIN / VALORES APROXIMADOS ####

MC_samples.tn = samples[[2]]

means <- NULL
means <- MC_samples.tn[, , 1:output_dim]  
# average over the MC samples
predictive_mean <- apply(means, 2, mean) 

epistemic_uncertainty <- apply(means, 2, var) 


logvar = NULL
logvar <- MC_samples.tn[, , (output_dim + 1):(output_dim * 2)]
aleatoric_uncertainty <- exp(colMeans(logvar))


df2 <- data.frame(
  x = Fecha[1:nrow(X_train)],
  y = denorm(y_train),
  y_pred = predictive_mean,
  e_u_lower = predictive_mean - sqrt(epistemic_uncertainty),
  e_u_upper = predictive_mean + sqrt(epistemic_uncertainty),
  a_u_lower = predictive_mean - sqrt(aleatoric_uncertainty),
  a_u_upper = predictive_mean + sqrt(aleatoric_uncertainty),
  u_overall_lower = predictive_mean - 
                    sqrt(epistemic_uncertainty) - 
                    sqrt(aleatoric_uncertainty),
  u_overall_upper = predictive_mean + 
                    sqrt(epistemic_uncertainty) + 
                    sqrt(aleatoric_uncertainty)
)



p2[[i]] = ggplot(df2, aes(x = x, y = y, group = 1)) + geom_line(colour = "blue") + 
  geom_line( aes(x = x, y = y_pred, colour = "red"))+   
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
  panel.background = element_blank(), axis.text.x = element_text(angle = 45), legend.position = "none" )+
  scale_x_discrete(breaks = everyother1) + labs (x = "Fecha", y = "Riesgo Relativo") +
  ggtitle(paste("Valores aproximados de training hasta el año:", Fechas_nom[i], sep = " "))+
  geom_ribbon(aes(ymin = u_overall_lower, ymax = u_overall_upper), alpha = 0.3)+
  ylim(-3, 10)


Eval.tn[i, 1:2] = as.numeric(metricas(df2))


#### VALORES AJUSTADOS TOTALES ####

MC_samples.tot = samples[[3]]

means <- NULL
means <- MC_samples.tot[, , 1:output_dim]  
# average over the MC samples
predictive_mean <- apply(means, 2, mean) 

epistemic_uncertainty <- apply(means, 2, var) 


logvar = NULL
logvar <- MC_samples.tot[, , (output_dim + 1):(output_dim * 2)]
aleatoric_uncertainty <- exp(colMeans(logvar))


df3 <- data.frame(
  x = Fecha,
  y = Alajuela$RR,
  y_pred = predictive_mean,
  e_u_lower = predictive_mean - sqrt(epistemic_uncertainty),
  e_u_upper = predictive_mean + sqrt(epistemic_uncertainty),
  a_u_lower = predictive_mean - sqrt(aleatoric_uncertainty),
  a_u_upper = predictive_mean + sqrt(aleatoric_uncertainty),
  u_overall_lower = predictive_mean - 
                    sqrt(epistemic_uncertainty) - 
                    sqrt(aleatoric_uncertainty),
  u_overall_upper = predictive_mean + 
                    sqrt(epistemic_uncertainty) + 
                    sqrt(aleatoric_uncertainty)
)



p3[[i]] = ggplot(df3, aes(x = x, y = y, group = 1)) + geom_line(colour = "blue") + 
  geom_line( aes(x = x, y = y_pred, colour = "red"))+   
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
  panel.background = element_blank(), axis.text.x = element_text(angle = 45), legend.position = "none" )+
  scale_x_discrete(breaks = everyother1) + labs (x = "Fecha", y = "Riesgo Relativo") +
  ggtitle(paste("Valores aproximados vs. RR observado, training antes del año:", Fechas_nom[i], sep = " "))+
  geom_ribbon(aes(ymin = u_overall_lower, ymax = u_overall_upper), alpha = 0.3)+
  ylim(-3, 10)


Eval.tot[i, 1:2] = as.numeric(metricas(df3))

}
```

# Resultados

```{r}

Metricas = cbind (Eval.pd, Eval.tn, Eval.tot)
colnames(Metricas) = c("Test NMRSE", "Test NIS", "Train NMRSE", "Train NIS", "Total NMRSE", "Total NIS")
rownames(Metricas) = c("2021", "2020 +", "2019 +", "2018 +", "2017+", "2016+", "2015+", "2014+", "2013+", "2012+", "2011+")
as.data.frame(Metricas)


```


# Gráficos

```{r}
p1
p2
p3

```