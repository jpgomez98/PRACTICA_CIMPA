---
title: "Modelos_paralelo"
author: "Jose Pablo Gómez Mata"
date: "2022-09-07"
output: html_document
---


### Paquetes

Se llaman los paquetes a utilizar.

```{r}
library(keras) # for deep learning
library(tidyverse) # general utility functions
library(caret) # machine learning utility functions
library(tibble)
library(readr)
library(ggplot2)
library(tensorflow)
library(neuralnet)
library(grid)
library(lubridate)
library(parallel) # programacion paralela
library(foreach)
library(doParallel)
```


## Datos


```{r}
load("base_cantones.RData")

basecanton = basecanton  %>% 
  
  dplyr::select(Canton, Year,Month,Nino34SSTA1, Nino34SSTA2, Nino34SSTA3, Nino34SSTA4, Nino34SSTA5, Nino34SSTA6, TNA1,TNA2, NDVI1, NDVI2, LSD1, LSD2, Precip_t1, Precip_t2, Precip_t3, Precip_t4, Precip_t5, Precip_t6, RRl1, RR) %>% 
  
  arrange(Canton,Year,Month) %>% ungroup() %>% mutate(Month=as.numeric(Month))

Cantones = unique(basecanton$Canton)




### Funciones ###

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
denorm <- function(x,base) {
  a = (x*(max(base$RR) - min(base$RR))+min(base$RR))
  return = a
}

 metricas <- function(tabla){
    NRMSE <- mean((tabla$y_pred-tabla$RR)^2)/mean(tabla$RR)
    NIS_95 <- mean((tabla$LS-tabla$LI)+
                   (2/0.05)*(tabla$LI-tabla$RR)*(tabla$RR<tabla$LI)+
                   (2/0.05)*(tabla$RR-tabla$LS)*(tabla$RR>tabla$LS))/mean(tabla$RR)
    return(data.frame(NRMSE,NIS_95))
  }
  
predice = function(x) {
  y_values = (model %>% predict(x))
  result = (y_values*(max(base$RR) - min(base$RR))+min(base$RR))
  return (as.numeric(result))
}





### Normalizar ###

basecanton2 = basecanton %>% group_by(basecanton$Canton) %>% 
  mutate_if(is.numeric, normalize)
basecanton2 = basecanton2[,-24]

#Clusters

Grupos = list()
Grupos[[1]] = Cantones[c(1,3,26)]
Grupos[[2]] = Cantones[c(2,7,25)]
Grupos[[3]] = Cantones[c(4,12,13)]
Grupos[[4]] = Cantones[c(5,17,27)]
Grupos[[5]] = Cantones[c(8,16,23)]
Grupos[[6]] = Cantones[c(14,15)]
Grupos[[7]] = Cantones[c(21,30)]
Grupos[[8]] = Cantones[c(11,22,29)]
Grupos[[9]] = Cantones[c(28,31)]
Grupos[[10]] = Cantones[c(9,18,24)]
Grupos[[11]] = Cantones[c(6,10)]
Grupos[[12]] = Cantones[c(19,20,32)]

#Train y test
data_train = as.data.frame(basecanton2) %>% filter(Year < 1)#PARA ENTRENAR HASTA 2018
data_test = as.data.frame(basecanton2) %>% filter(Year >= 1)
X_train = data_train[,-ncol(data_train)]
y_train = as.data.frame(data_train[,c("Canton","RR")])
X_test = as.data.frame(data_test[,-ncol(data_test)])
y_test = as.data.frame(data_test[,c("Canton","RR")])
Fecha = paste(basecanton$Year, basecanton$Month)
Fecha = Fecha[1:235]
Mes = basecanton$Month
Mes = Mes[1:235]
```

# Prog. Paralela
```{r}
n.cores <- round(detectCores() / 2)
n.cores
# 
cl<-makeCluster(n.cores)
# registerDoParallel(cl)
# nep <- 45

```

# Arquitectura del modelo


```{r}
model <- keras_model_sequential()
# our input layer
model %>% 
    layer_simple_rnn(units = 100, input_shape = c(ncol(X_train)-1,1), activation='tanh', 
                   kernel_initializer= initializer_constant(0.5),
                   bias_initializer=initializer_zeros()) %>% 
  layer_dense(units = 50, activation = "relu")%>%
  layer_dense(units = 50, activation = "relu")%>%
  layer_dense(units = 50, activation = "relu")%>%
  layer_dropout(rate = 0.1)%>%
  layer_dense(units = 25, activation = "relu")%>%
  layer_dense(units = 25, activation = "relu")%>%
  layer_dense(units = 25, activation = "relu")%>%
  layer_dropout(rate = 0.1)%>%
  layer_dense(units = 12, activation = "relu")%>%
  layer_dense(units = 12, activation = "relu")%>%
  layer_dropout(rate = 0.1)%>%
  layer_dense(units = 6, activation = "relu")%>%
  layer_dense(units = 6, activation = "relu")%>%
  
  layer_dense(units = 1, activation = "sigmoid")

```


# Entrenamiento y predicciones

```{r}


Eval.pd = matrix(ncol = 2, nrow = length(Cantones))
Eval.tot = matrix(ncol = 2, nrow = length(Cantones))
p1 = list()
p2 = list()
p3 = list()
df1 = list()
df2 = list()
df3 = list()

count = 0
start_time <- Sys.time() # para tomar el tiempo



parSapply(cl = cl,
          1:12,
          )

function (i in 1:12) {

  X_trainc = X_train %>% filter(Canton %in% Grupos[[i]])
  y_trainc = y_train %>% filter(Canton %in% Grupos[[i]])

  
  X_testc = X_test %>% filter(Canton %in% Grupos[[i]])
  y_testc = y_test %>% filter(Canton %in% Grupos[[i]])


  
  
  model %>% compile(loss = "mse", 
                    optimizer = optimizer_adam(lr = 0.0005),
                    metric = "mean_absolute_error")
  
  trained_model <- model %>% fit(
    x =  as.matrix(X_trainc[,-1]), 
    y = as.matrix(y_trainc[,-1]), 
    batch_size = 18, 
    epochs = 45, 
    validation_split = 0.1,
    shuffle = F) 
  
  
  for (j in 1:length(Grupos[[i]])) {
    
    count = count + 1
    
    pred = NULL
    
    xts = X_testc %>% filter(Canton == Grupos[[i]][j])
    xts = as.matrix(xts[,-1])
    
    xtr = X_trainc %>% filter(Canton == Grupos[[i]][j])
    xtr = as.matrix(xtr[,-1])
    
    base = data.frame(basecanton2 %>% filter(Canton == Grupos[[i]][j]) %>% dplyr::select(RR))
    yts = as.matrix(denorm((y_testc %>% filter(Canton == Grupos[[i]][j]))[,-1], base))
      
    # predicciones a 3 meses
    for (k in 1:2) {
      pred[k] = predice(xts)[k]
      xts[k+1,21] = pred[k]
    } 
    pred[3] = predice(xts)[3]
    
    
   
    # Se crea una base para las predicciones, "df1", que tiene los valores predichos, los valores reales, fecha y mes.
    df1[[count]] = as.data.frame(cbind(pred, yts, Fecha[233:235],Mes[233:235]))
    colnames(df1[[count]]) = c("y_pred", "RR", "Fecha","Mes")
    df1[[count]]$RR = as.numeric(df1[[count]]$RR)
    df1[[count]]$y_pred = as.numeric(df1[[count]]$y_pred)
    
  
   
    #### VALORES APROXIMADOS ####
    ## Generar valores ajustados
    
    df2[[count]] = as.data.frame(cbind(predice(xtr[1:232,]), base$RR[1:232], Fecha[1:232], Mes[1:232]))
    colnames(df2[[count]]) = c("y_pred", "RR", "Fecha","Mes")
    df2[[count]]$RR = as.numeric(df2[[count]]$RR)
    df2[[count]]$y_pred = as.numeric(df2[[count]]$y_pred)
    df2[[count]] = rbind(df2[[count]], df1[[count]])
    
    everyother1 <- function(x) x[(seq_along(Fecha) + 5)%%12 == 6]
    
    # aqui hago las predicciones del 2000 hasta el 2020 con intervalos de bootstrap
    
    LI = matrix(ncol = 1, nrow = 235)
    LS = matrix(ncol = 1, nrow = 235)
    for (w in 1:12) {
      
      indx = which(df2[[count]]$Mes== w)
      x <- df2[[count]][Mes==w,1] # tomo el mes w con las predicciones para cada mes (es decir que tomo el mes w para los años que hayan reportados)
      x <- as.numeric(x)
      n <- length(x) # voy a hacer un remuestreo para la cantidad de observaciones que tenga de ese mes w
      Tn <- mean(x) # saco la media para estos datos
      
      B <- 500
      Tboot_b <- NULL
      for(b in 1:B) {  
        xb <- sample(x, size = n, replace = TRUE)  
        Tboot_b[b] <- mean(xb)
      }
      # calculo de estadisticos de bootstrap
      Tboot <- mean(Tboot_b)
      Vboot <- var(Tboot_b)
      sdboot <- sqrt(Vboot)
      
      # ahora el IC de bootstrap estudentizado
      B <- 500
      Tboot_b <- NULL
      Tboot_bm <- NULL
      sdboot_b <- NULL
      
      for (b in 1:B) {  
        xb <- sample(x, size = n, replace = TRUE)  
        Tboot_b[b] <- mean(xb) # la media
        for (m in 1:B) {    
          xbm <- sample(xb, size = n, replace = TRUE)    
          Tboot_bm[m] <- mean(xbm)  
        }  
        sdboot_b[b] <- sd(Tboot_bm)
      }
      
      z_star <- (Tboot_b - Tn) / sdboot_b
      
      # se crean los limites inferiores y superiores
      LI[indx,] = as.numeric(df2[[count]][Mes==w,1]) - quantile(z_star, 1 - 0.05 / 2) * sdboot
      LS[indx,] = as.numeric(df2[[count]][Mes==w,1]) - quantile(z_star, 0.05 / 2) * sdboot
    }
    
    
    
    #Añadir límites a la base df2
    
  
    df2[[count]] = cbind(df2[[count]], LI, LS)
    df1[[count]] = cbind(df1[[count]], LI[233:235], LS[233:235])
    colnames(df1[[count]]) = c("y_pred","RR","Fecha","Mes","LI","LS")
    
    df3[[count]] = df2[[count]][185:235,]
  
    
    #Gráficos
      
    
    p1[[count]] = ggplot(df1[[count]], aes(x = Fecha, y = RR, group = 1)) + geom_line(colour = "blue") + 
      geom_line( aes(x = Fecha, y = y_pred, colour = "red"))+   
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
            panel.background = element_blank(), axis.text.x = element_text(angle = 45), legend.position = "none" )+
      labs (x = "Fecha", y = "Riesgo Relativo") + geom_ribbon(aes(ymin= LI,ymax= LS), alpha=0.2, fill = "red") +
      ggtitle(paste("Predicciones 2021 del cantón", Cantones[count], sep = " "))
    
    
    p2[[count]] = ggplot(df2[[count]], aes(x = Fecha, y = RR, group = 1)) + geom_line(colour = "blue") + 
      geom_line(aes(x = Fecha, y = y_pred, colour = "red"))+   
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
            panel.background = element_blank(), axis.text.x = element_text(angle = 45), legend.position = "none" )+
      scale_x_discrete(breaks = everyother1) + labs (x = "Fecha", y = "Riesgo Relativo") +
      geom_ribbon(data = df1[[count]], aes(ymin = LI,ymax= LS), alpha=0.5, fill = "red") +
      # scale_y_continuous(breaks = seq(min(RR), max(RR), 10)) +
      ggtitle(paste(Cantones[count]))
    
    p3[[count]] = ggplot(df3[[count]], aes(x = Fecha, y = RR, group = 1)) + geom_line(colour = "blue") + 
      geom_line(aes(x = Fecha, y = y_pred, colour = "red"))+   
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
            panel.background = element_blank(), axis.text.x = element_text(angle = 45), legend.position = "none" )+
      scale_x_discrete(breaks = everyother1) + labs (x = "Fecha", y = "Riesgo Relativo") +
      geom_ribbon(data = df1[[count]], aes(ymin = LI,ymax= LS), alpha=0.5, fill = "red") +
      # scale_y_continuous(breaks = seq(min(RR), max(RR), 10)) +
      ggtitle(paste("Últimos 4 años: ", Cantones[count]))
    
  
    
    
    
    Eval.pd[count,] = as.numeric(metricas(df1[[count]]))
    Eval.tot[count,] = as.numeric(metricas(df2[[count]]))
    
    
    k_clear_session()
  
  
  }
}
finish_time <- Sys.time()

#Tiempo de procesamiento
finish_time - start_time
```

```{r}
df1[[1]]

```

## Resultados de métricas

```{r}
Metricas = cbind (round(Eval.pd,2), round(Eval.tot,2))
colnames(Metricas) = c("NMRSE 2021", "NIS 2021", "NMRSE Total", "NIS total")
rownames(Metricas) = Cantones
as.data.frame(Metricas)
```

## Sobre ajuste

```{r}
sobreajuste = Metricas[,1]/Metricas[,3]

library(ggplot2)

sobreajuste = cbind(Cantones, sobreajuste)
sobreajuste = as.data.frame(sobreajuste)
colnames(sobreajuste) = c("Cantón", "SobreAjuste")
sobreajuste$SobreAjuste = as.numeric(sobreajuste$SobreAjuste)


ggplot(sobreajuste, aes(y = Cantón,x = 1, fill = SobreAjuste)) + 
  geom_tile() +  scale_fill_stepsn(
  breaks = c(1.5, 5, 20, 100, 150, 1000),
  colours = c( "green", "yellow", "orange", "red"),
  values = NULL,
  space = "Lab",
  na.value = "grey50",
  guide = "legend",
  aesthetics = "fill")

```


## Gráficos

```{r}
p1
p2
p3
```


## Acomodo resumido de los gráficos

Se acomodan los gráficos con valores ajustados y predichos según los grupos formados por semejanza en el RR.

### Graficos 1

```{r}
# creo la "hoja en blanco"
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 3, ncol = 3)))

# una funcion que simplifica el acomodo de los graficos
define_region <- function(row, col){
  viewport(layout.pos.row = row, layout.pos.col = col)
}

print(p2[[12]], vp = define_region(row = 1, col = 1))
print(p2[[4]], vp = define_region(row = 1, col = 2))
print(p2[[13]], vp = define_region(row = 1, col = 3))
print(p2[[17]], vp = define_region(row = 2, col = 1))
print(p2[[5]], vp = define_region(row = 2, col = 2))
print(p2[[27]], vp = define_region(row = 2, col = 3))
print(p2[[23]], vp = define_region(row = 3, col = 1))
print(p2[[8]], vp = define_region(row = 3, col = 2))
print(p2[[16]], vp = define_region(row = 3, col = 3))

```


### Graficos 2

```{r}
# creo la "hoja en blanco"
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 3, ncol = 3)))

# una funcion que simplifica el acomodo de los graficos
define_region <- function(row, col){
  viewport(layout.pos.row = row, layout.pos.col = col)
}

print(p2[[14]], vp = define_region(row = 1, col = 1))
print(p2[[15]], vp = define_region(row = 1, col = 2))
print(p2[[21]], vp = define_region(row = 1, col = 3))
print(p2[[30]], vp = define_region(row = 2, col = 1))
print(p2[[22]], vp = define_region(row = 2, col = 2))
print(p2[[11]], vp = define_region(row = 2, col = 3))
print(p2[[29]], vp = define_region(row = 3, col = 1))
print(p2[[28]], vp = define_region(row = 3, col = 2))
print(p2[[31]], vp = define_region(row = 3, col = 3))

```

### Graficos 3

```{r}
# creo la "hoja en blanco"
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 2, ncol = 3)))

# una funcion que simplifica el acomodo de los graficos
define_region <- function(row, col){
  viewport(layout.pos.row = row, layout.pos.col = col)
}

print(p2[[7]], vp = define_region(row = 1, col = 1))
print(p2[[1]], vp = define_region(row = 1, col = 2))
print(p2[[25]], vp = define_region(row = 1, col = 3))
print(p2[[26]], vp = define_region(row = 2, col = 1))
print(p2[[2]], vp = define_region(row = 2, col = 2))
print(p2[[3]], vp = define_region(row = 2, col = 3))

```

### Graficos 4

```{r}
# creo la "hoja en blanco"
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 4, ncol = 3)))

# una funcion que simplifica el acomodo de los graficos
define_region <- function(row, col){
  viewport(layout.pos.row = row, layout.pos.col = col)
}

print(p2[[18]], vp = define_region(row = 1, col = 1:3))
print(p2[[9]], vp = define_region(row = 2, col = 1))
print(p2[[24]], vp = define_region(row = 2, col = 2))
print(p2[[6]], vp = define_region(row = 2, col = 3))
print(p2[[10]], vp = define_region(row = 3, col = 1))
print(p2[[32]], vp = define_region(row = 3, col = 2))
print(p2[[19]], vp = define_region(row = 3, col = 3))
print(p2[[20]], vp = define_region(row = 4, col = 1:3))
```




























